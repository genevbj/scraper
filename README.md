# scraper
Web scraper

TODO

1. Retrieve all data (html parts and images) from page via headless chrome in node js script
2. Store HTML/XML and supplied image files in multilevel cache (a/b/c/abcxxxxxx.xml)
3. Store proxies list in DB
4. Make analyzer of accessability of proxy as standalone script
5. Make some API to add|remove proxy to list via http request
6. Make HTTP  errors handler
7. Parse html page for additional info (not described in config)
8. Reparse HTML pages from cache
9. Switch proxy on the run
10. Using chrome browsers simultaneously with different proxy settings (parallel downloads)
